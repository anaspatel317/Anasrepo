{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OvJB7m3J27B7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V821xhrE3Ozn",
    "outputId": "3e1cfcce-1cd7-4098-c128-87771a902aa5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2500</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>110.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3150</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>109.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>4000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>6300</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>104.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x0    x1      x2    x3        x4        y\n",
       "0      800   0.0  0.3048  71.3  0.002663  126.201\n",
       "1     1000   0.0  0.3048  71.3  0.002663  125.201\n",
       "2     1250   0.0  0.3048  71.3  0.002663  125.951\n",
       "3     1600   0.0  0.3048  71.3  0.002663  127.591\n",
       "4     2000   0.0  0.3048  71.3  0.002663  127.461\n",
       "...    ...   ...     ...   ...       ...      ...\n",
       "1498  2500  15.6  0.1016  39.6  0.052849  110.264\n",
       "1499  3150  15.6  0.1016  39.6  0.052849  109.254\n",
       "1500  4000  15.6  0.1016  39.6  0.052849  106.604\n",
       "1501  5000  15.6  0.1016  39.6  0.052849  106.224\n",
       "1502  6300  15.6  0.1016  39.6  0.052849  104.204\n",
       "\n",
       "[1503 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"airfoil_noise_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tcVivzCsHsS",
    "outputId": "c61a5154-a987-4b19-cac4-243c807f953a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         x0    x1      x2    x3        x4        y\n",
       "0      800   0.0  0.3048  71.3  0.002663  126.201\n",
       "1     1000   0.0  0.3048  71.3  0.002663  125.201\n",
       "2     1250   0.0  0.3048  71.3  0.002663  125.951\n",
       "3     1600   0.0  0.3048  71.3  0.002663  127.591\n",
       "4     2000   0.0  0.3048  71.3  0.002663  127.461\n",
       "...    ...   ...     ...   ...       ...      ...\n",
       "1498  2500  15.6  0.1016  39.6  0.052849  110.264\n",
       "1499  3150  15.6  0.1016  39.6  0.052849  109.254\n",
       "1500  4000  15.6  0.1016  39.6  0.052849  106.604\n",
       "1501  5000  15.6  0.1016  39.6  0.052849  106.224\n",
       "1502  6300  15.6  0.1016  39.6  0.052849  104.204\n",
       "\n",
       "[1503 rows x 6 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GnXeHMCb37m2"
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, var_red=None, value=None):\n",
    "        ''' constructor ''' \n",
    "        \n",
    "        # for decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.var_red = var_red\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eUrExOYX382X"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor():\n",
    "    def __init__(self, min_samples_split=5, max_depth=3):\n",
    "        ''' constructor '''\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree '''\n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        best_split = {}\n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"var_red\"]>0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"var_red\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_var_red = -float(\"inf\")\n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_var_red = self.variance_reduction(y, left_y, right_y)\n",
    "                    # update the best split if needed\n",
    "                    if curr_var_red>max_var_red:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"var_red\"] = curr_var_red\n",
    "                        max_var_red = curr_var_red\n",
    "                        \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def variance_reduction(self, parent, l_child, r_child):\n",
    "        ''' function to compute variance reduction '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        reduction = np.var(parent) - (weight_l * np.var(l_child) + weight_r * np.var(r_child))\n",
    "        return reduction\n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        val = np.mean(Y)\n",
    "        return val\n",
    "                \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.var_red)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict a single data point '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CT4dSSNd4Hll"
   },
   "outputs": [],
   "source": [
    "#X = data.iloc[:, :-1].values\n",
    "#Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5SwKybQ7uDht"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RBy2pL7Zy_qE"
   },
   "outputs": [],
   "source": [
    "# Select ratio\n",
    "ratio = 0.75\n",
    "\n",
    "n_train = int(X.shape[0] *ratio)\n",
    "n_test = X.shape[0] - n_train\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "# Split data into test and train\n",
    "X_train = X[indices[:n_train], :]\n",
    "Y_train = Y[indices[:n_train], :]\n",
    "X_test = X[indices[n_train:], :]\n",
    "Y_test = Y[indices[n_train:], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2GdUDarzMDm",
    "outputId": "c58c7821-e32b-48b4-a99c-7d8a15999ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1127, 5), (376, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7bUs5chw4LMS"
   },
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=3, max_depth=3)\n",
    "regressor.fit(X_train,Y_train)\n",
    "#regressor.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPQUxUYA4ScJ",
    "outputId": "8317454c-70fa-4e50-c011-0589fbca8607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.649233081958436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = regressor.predict(X_test) \n",
    "from sklearn.metrics import mean_squared_error \n",
    "np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvhdtCKt6rLl",
    "outputId": "ef1d768e-f4ab-423a-dce7-8cce29f77bae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.561088220775719"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "(mean_absolute_error(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for the model is 0.5609816220166748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score( Y_test, Y_pred)\n",
    "print('r2 score for the model is', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 10, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "max_depths = [1,2,3, 4,5, 6,7, 8,9,10]\n",
    "min_samples_splits = [2,3, 4,5, 6,7, 8,9,10]\n",
    "\n",
    "\n",
    "def grid_search_decision_tree(max_depths, min_samples_splits, X, Y):\n",
    "    best_params = None\n",
    "    best_mse = float('inf')\n",
    "    for max_depth, min_samples_split in product(max_depths, min_samples_splits):\n",
    "    \n",
    "        # Create a decision tree regressor with the current hyperparameters\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, Y_train)\n",
    "        # Predict the target for the test data\n",
    "        Y_pred = model.predict(X_test)\n",
    "        # Calculate the mean squared error\n",
    "        mse = mean_squared_error(Y_test, Y_pred)\n",
    "        # If the mean squared error is better than the previous best,\n",
    "        # update the best hyperparameters and mean squared error\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {'max_depth': max_depth, 'min_samples_split': min_samples_split}\n",
    "    return best_params\n",
    "best_params = grid_search_decision_tree(max_depths, min_samples_splits, X, Y)\n",
    "print(f'Best hyperparameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6hcNydR1NLC",
    "outputId": "cc9a0304-4b90-4576-f3cf-76381d7dd256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 8.040547775357323\n",
      "Best params: {'max_depth': 9, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to search over\n",
    "param_dist = {\n",
    "    'max_depth': np.arange(1, 10),\n",
    "    'min_samples_split': np.arange(2, 10)\n",
    "}\n",
    "\n",
    "# Define the number of iterations to run\n",
    "n_iter = 10\n",
    "\n",
    "# Initialize the best score and best parameters\n",
    "best_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Perform random search over hyperparameters\n",
    "for i in range(n_iter):\n",
    "    # Randomly select hyperparameters from param_dist\n",
    "    params = {}\n",
    "    for param_name, param_values in param_dist.items():\n",
    "        params[param_name] = np.random.choice(param_values)\n",
    "    \n",
    "    # Train and evaluate a decision tree regressor with the selected hyperparameters\n",
    "    regressor = DecisionTreeRegressor(**params)\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    Y_pred = regressor.predict(X_test)\n",
    "    score = mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    # Update the best score and best parameters if necessary\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: {}\".format(best_score))\n",
    "print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=3, max_depth=10)\n",
    "regressor.fit(X_train,Y_train)\n",
    "#regressor.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7020322350989003"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = regressor.predict(X_test) \n",
    "from sklearn.metrics import mean_squared_error \n",
    "np.sqrt(mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for the model is 0.8517136710457757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print('r2 score for the model is', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=3, max_depth=9)\n",
    "regressor.fit(X_train,Y_train)\n",
    "#regressor.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8312159142916435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = regressor.predict(X_test) \n",
    "from sklearn.metrics import mean_squared_error \n",
    "np.sqrt(mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for the model is 0.8371956353882314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print('r2 score for the model is', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
